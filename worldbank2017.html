<!doctype html>
<html lang="en">
<!-- This is a generated file. Do not edit. -->

    <head>
        <meta charset="utf-8">

        <title>Tangibly Smart</title>

        <meta name="description" content="Slides for Tangible Landscape at World Bank 2017 talk">
        <meta name="author" content="NCSU GeoForAll Lab members">

        <meta name="apple-mobile-web-app-capable" content="yes" />
        <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

        <link rel="stylesheet" href="css/reveal.css">
        <link rel="stylesheet" href="css/theme/osgeorel_greyscale.css" id="theme">

        <!-- For syntax highlighting -->
        <link rel="stylesheet" href="lib/css/zenburn.css">
        <!-- For chalkboard plugin -->
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">

        <!-- If the query includes 'print-pdf', include the PDF print sheet -->
        <script>
            if( window.location.search.match( /print-pdf/gi ) ) {
                var link = document.createElement( 'link' );
                link.rel = 'stylesheet';
                link.type = 'text/css';
                link.href = 'css/print/pdf.css';
                document.getElementsByTagName( 'head' )[0].appendChild( link );
            }
        </script>

        <!--[if lt IE 9]>
        <script src="lib/js/html5shiv.js"></script>
        <![endif]-->

        <style>
        body {
        /*background-color: #FFF !important;*/
        /*
          background-image: url("pictures/elevation-nagshead.gif");
          background-repeat: no-repeat;
          background-position: left bottom;*/
        }
        .reveal section img {
            background: transparent;
            border: 0;
            box-shadow: 0 0 0 rgba(0, 0, 0, 0.15);
        }
        /* for standalone frame */
        /*
        iframe {
            display: block;
            margin-left: auto;
            margin-right: auto;
        }
        */
        /* display: inline; background-color: #002B36; padding: 0px; margin: 0px */
        .rounded-corners {
            border: 0px solid black;
            border-radius: 5px;
            -moz-border-radius: 5px;
            -khtml-border-radius: 5px;
            -webkit-border-radius: 5px;
        }
        a:hover {
            color: #444 !important;
            text-decoration: underline !important;
        }
        h1, h2, h3, h4, h5 {
            text-transform: none !important;
            /* word-break: keep-all; text-transform: none; font-size: 200%; line-height: 110%; */
            /* color: #060 !important; */
            /* color: #444 !important; */ /* grey from the wab page */
            font-weight: bold !important;
            -webkit-hyphens: none !important;
            -moz-hyphens: none !important;
            -ms-hyphens: none !important;
            hyphens: none !important;
            line-height: 110% !important;
        }
        .reveal .progress span {
            background-color: #444 !important;
        }
        /* predefined element positioning */
        .top {
            /*position: relative;*/
            top: 5%;
            height: 45%; /* is the height even needed? */
        }
        .bottom {
            height: 45%;
        }
        .ne {
            position: absolute;
            top: 5%;
            right: 5%;
            height: 45%;
            width: 45%;
        }
        .nw {
            position: absolute;
            top: 5%;
            left: 5%;
            height: 45%;
            width: 45%;
        }
        .se {
            position: absolute;
            bottom: 5%;
            right: 5%;
            height: 45%;
            width: 45%;
        }
        .sw {
            position: absolute;
            bottom: 5%;
            left: 5%;
            height: 45%;
            width: 45%;
        }

        /* classes for sections with predefined elements */
        /* using !important because, reveal styles are applied afterwards  */
        .right, .textimg > img, .textimg > video, .textimg > iframe, .imgtext > p, .imgtext > ul, .imgtext > ol, .imgtext > div {
            float: right;
            text-align: left;
            max-width: 47% !important;
        }
        .left, .imgtext > img, .imgtext > video, imgtext > iframe, .textimg > p, .textimg > ul, .textimg > ol, .textimg > div {
            float: left;
            text-align: left;
            max-width: 47% !important;
        }
        li > ul, li > ol {
            font-size: 85% !important;
            line-height: 110% !important;
        }
        .small {
            font-size: smaller !important;
            color: gray;
            margin: 0.1em !important;
        }
        .credit {
            font-size: small !important;
            color: gray;
            margin: 0.1em !important;
        }
        </style>
    </head>

    <body>

        <div class="reveal">

            <!-- Any section element inside of this container is displayed as a slide -->
            <div class="slides">

<section>
<h5 style="color: #888">Watershed Days 2017</h5>
<h1 style="margin-top: 0.5em; margin-bottom: 0em; color: #000">Tangibly Smart</h1>
<h2 style="margin-top: 0.1em; margin-bottom: 0em; color: #000">An interactive watershed in your hands</h2>
<h5 style="margin-top: 0.9em;color: #888">Brendan Harmon, Anna Petrasova, Payam Tabrizian, Vaclav Petras, &amp; Helena Mitasova</h5>
<img height="50px" style="margin-top: 1em" src="img/ncstate-type-4x1-blk-max.png">
<p></p>
<img height="80px" style="margin-top: -0.75em" src="img/cgaBlack.png">
<aside class="notes">
</aside>
</section>

<!--
<aside class="notes">
  The talk is presented by the GeoForAll Laboratory at the
  Center for Geospatial Analytics (CGA), North Carolina State University
  CGA is an interdisciplinary research and education center with focus on
  geospatial computing, modeling, analytics and geovisualization.
  which is a project we developed as members of GeoForAll laboratory
  to make landscape design process more effective through the use of Tangible
  interaction, Immersive virtual environments, and geospatial analytics.
  Our lab is part of the Center for Geospatial Analytics, which focuses
  on educationa nd interdisciplinary research, and has been instrumental in
  making this research happen.
</aside>
-->

<!-- Tangible Landscape -->
<section data-background="img/tangible_landscape.jpg">
<h1 class="shadow">Tangible Landscape</h1>
<h3 class="shadow">A tangible user interface powered by open source GIS</h3>
<img height="200px" src="img/grass_logo_black_outlined.png">
</section>

<!-- Demo -->
<section>
<h2>Tanigble interaction with GIS</h2>
<video  data-autoplay class="stretch" style="margin-top: 1em" controls>
<source src="video/tl_flow.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<p>With Tangible Landscape you can hold a
watershed <!-- GIS -->
in your hands -
feeling the shape of the earth,
sculpting its topography,
and directing the flow of water.</p>
</section>

<!-- Motivation -->
<section>
<h2>Why tangible?</h2>
<ul>
  <li>Using your body is natural</li>
  <li>Using a mouse and keyboard is not natural</li>
  <li>Collaborating with a mouse and keyboard is really hard</li>
  <li>Interating with scientific models is even harder</li>
</ul>
</section>

<!-- How-it-works -->
<section>
<h2>How it works</h2>
<img class="stretch" src="img/rendered_diagram_1.png">
<p>Tangible Landscape couples a digital and a physical model
through a continuous cycle of 3D scanning,
geospatial computation, and projection</p>
</section>

<!-- Scanning -->
<section>
<h2>Realtime 3D scanning</h2>
<img class="stretch" src="img/fusion.jpg">
<p>with Kinect sensor</p>
</section>

<!-- Interactions -->
<section>
<h2>Interactions</h2>
<img class="stretch" src="img/interaction_schema.jpg">
<table width="100%">
        <col width="20%">
        <col width="20%">
        <col width="20%">
        <col width="20%">
        <col width="20%">
        <tr>
            <td style="vertical-align: middle; text-align:center; border-bottom: 0px; padding: 0;">sculpting
            <td style="vertical-align: middle; text-align:center; border-bottom: 0px; padding: 0;">excavation
            <td style="vertical-align: middle; text-align:center; border-bottom: 0px; padding: 0;">patches
            <td style="vertical-align: middle; text-align:center; border-bottom: 0px; padding: 0;">points
            <td style="vertical-align: middle; text-align:center; border-bottom: 0px; padding: 0;">directions
        </tr>
</table>
</section>

<!-- GRASS GIS for watershed analysis
<section>
<h2><a href="https://grasswiki.osgeo.org/wiki/Hydrological_Sciences">Watershed analysis</a> in</h2>
<img style="margin-top: -0.2em" height="125px" src="img/logo_black.png">
<p></p>
<ul style="font-size:0.8em">
<li><a href="https://grass.osgeo.org/grass72/manuals/r.watershed.html">r.watershed</a></li>
<li><a href="https://grasswiki.osgeo.org/wiki/R.stream.*_modules">r.stream*</a></li>
<li><a href="https://grass.osgeo.org/grass72/manuals/r.sim.water.html">r.sim.water</a></li>
<li><a href="https://grass.osgeo.org/grass72/manuals/r.sim.sediment.html">r.sim.sediment</a></li>
<li><a href="https://grass.osgeo.org/grass72/manuals/r.lake.html">r.lake</a></li>
<li><a href="https://grass.osgeo.org/grass72/manuals/addons/r.hydrodem.html">r.hydrodem</a></li>
<li>etc...</li>
</ul>
</section>
-->

<section>
<h2><a href="https://grasswiki.osgeo.org/wiki/Hydrological_Sciences">Watershed analysis</a> in</h2>
<img style="margin-top: -0.2em" height="125px" src="img/logo_black.png">
<p></p>
<table>
  <tr>
    <td><a href="https://grass.osgeo.org/grass72/manuals/r.watershed.html">r.watershed</a></td>
    <td><a href="https://grasswiki.osgeo.org/wiki/R.stream.*_modules">r.stream*</a></td>
  </tr>
  <tr>
    <td><a href="https://grass.osgeo.org/grass72/manuals/r.sim.water.html">r.sim.water</a></td>
    <td><a href="https://grass.osgeo.org/grass72/manuals/r.sim.sediment.html">r.sim.sediment</a></td>
  </tr>
  <tr>
    <td><a href="https://grass.osgeo.org/grass72/manuals/r.lake.html">r.lake</a></td>
    <td><a href="https://grass.osgeo.org/grass72/manuals/addons/r.hydrodem.html">r.hydrodem</a></td>
  </tr>
  <tr>
    <td><a href="https://grass.osgeo.org/grass72/manuals/r3.gwflow.html">r3.gwflow</a></td>
    <td><a href="https://grass.osgeo.org/grass72/manuals/r.fill.dir.html">r.fill.dir</a></td>
  </tr>
  <tr>
    <td><a href="https://grass.osgeo.org/grass72/manuals/r.carve.html">r.carve</a></td>
    <td><a href="https://grass.osgeo.org/grass72/manuals/r.drain.html">r.drain</a></td>
  </tr>
  <tr>
    <td style="border: none"><a href="https://grass.osgeo.org/grass72/manuals/addons/r.damflood.html">r.dam.flood</a></td>
    <td style="border: none">etc...</td>
  </tr>
</table>
</ul>
</section>

<!-- Applications -->
<section data-background-image="img/tl_3d_planting.jpg">
<h1 class="shadow">Applications</h1>
</section>

<!-- Planting -->
<section data-background-image="img/background_interaction_felt.png">
<h2>Applications: 3D Planting</h2>
<img width="32%" src="img/tl_planting_1.jpg">
<img width="32%" src="img/tl_planting_2.jpg">
<img width="32%" src="img/tl_planting_3.jpg">
<!--<img width="23%" src="img/tl_planting_4.jpg">-->
<p>Planting patches of 3D trees by placing pieces of color coded felt and markers.</p>
</section>

<section data-background-image="img/background_interaction_felt.png">
<h2>Applications: 3D planting</h2>
<video  id="planting_video" data-autoplay class="stretch" style="margin-top: 1em" controls>
<source src="video/case_study_video.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<script>
document.getElementById("planting_video").currentTime = 83;
</script>
<p>Planting patches of 3D trees by placing pieces of color coded felt.</p>
</section>

<!-- Erosion control -->
<section data-background-image="img/background_interaction_felt.png">
<h2>Applications: erosion control</h2>
<!--<img width="900px" src="img/felt/felt.png">-->
<img width="23%" src="img/felt/felt_1.jpg">
<img width="23%" src="img/felt/felt_2.jpg">
<img width="23%" src="img/felt/felt_3.jpg">
<img width="23%" src="img/felt/felt_4.jpg">
<p><b>Modifying land cover with colored felt</b> -
adding grass (light green) and patches of trees (darker green)
changes the c-factor thus reducing erosion.
</p>
</section>

<!-- Subsurface soil moisture -->
<section data-background-image="img/background_interaction_hands_markers.png">
<h2>Applications: 3D soil moisture exploration</h2>
<img height="190px" src="img/subsurface_1.jpg">
<img height="190px" src="img/subsurface_2.jpg">
<img height="190px" src="img/subsurface_3.jpg">
<!--<img width="80%" src="img/subsurface_cross_section.png">-->
</section>

<section>
<h2>Applications: 3D soil moisture exploration</h2>
<video  data-autoplay class="stretch" style="margin-top: 1em" controls>
<source src="video/tl_subsurface.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<p>Exploring subsurface volumes as if digging with an excavator.</p>
</section>

<!-- Dam breach -->
<section>
<h2>Applications: Dam breach simulation</h2>
<video  data-autoplay class="stretch" style="margin-top: 1em" controls>
<source src="video/dam_breach_3.mp4" type="video/mp4">
Your browser does not support the video tag.
</video>
<p>Simulate dam breach scenarios.</p>
</section>

<!-- Coastal flooding -->
<section data-background-image="img/background_interaction_hands.png">
<h2>Applications: coastal flooding</h2>
<img width="32%" src="img/tl_coastal_1s.png">
<img width="32%" src="img/tl_coastal_2s.png">
<img width="32%" src="img/tl_coastal_4s.png">
<p>Building coastal defenses to save homes from storm surge</p>
</section>

<!-- Open source -->
<section>
<h2>Open source</h2>
<img width="18%" src="img/tl_logo.png">
<p>Tangible Landscape plugin for GRASS GIS <br>
    <a href="https://github.com/tangible-landscape/grass-tangible-landscape">
        <small>github.com/tangible-landscape/grass-tangible-landscape</small>
    </a></p>
<p>GRASS GIS module for importing data from Kinect v2 <br>
    <a href="https://github.com/tangible-landscape/r.in.kinect">
        <small>github.com/tangible-landscape/r.in.kinect</small>
    </a></p>
<p>Tangible Landscape repository on Open Science Framework <br>
    <a href="https://osf.io/w8nr6/">
        <small>osf.io/w8nr6</small>
    </a></p>
</section>

<!-- Equipment list and budget -->
<section>
<h2>Build your own!</h2>
<table style="font-size:0.6em">
<tr><th>Type</th><th>Product example</th><th>Cost</th></tr>
<tr><td>Software</td><td>Tangible Landscape plugin for GRASS GIS</td><td>$0</td></tr>
<tr><td>Computer</td><td>System76 Oryx Pro</td><td>$1500</td></tr>
<tr><td>Display</td><td>Samsung 23.6-Inch UHD-QHD Monitor</td><td>$350</td></tr>
<tr><td>Projector</td><td>Epson PowerLite 1761W</td><td>$600</td></tr>
<tr><td>3D sensor</td><td>Xbox One Kinect</td><td>$100</td></tr>
<tr><td></td><td>Kinect Adapter for Windows</td><td>$40</td></tr>
<tr><td>Stand</td><td>Avenger 40-Inch C-Stand with Grip Kit</td><td>$200</td></tr>
<tr><td></td><td>2 x Avenger 3-Inch Baby Wall Plate with Swivel Pin</td><td>$80</td></tr>
<tr><td></td><td>Kupo Convi Clamp with Adjustable Handle</td><td>$25</td></tr>
<tr><td></td><td>Kupo Grip Head with Hex Stud</td><td>$30</td></tr>
<tr><td></td><td>Kupo 20-Inch Hex Grip Arm</td><td>$40</td></tr>
<tr><td>Peripherals</td><td>HDMI cable, extension cord</td><td>$20</td></tr>
<tr><td>Modeling media</td><td>Waba Fun Kinetic Sand 11 Lbs</td><td>$50</td></tr>
<tr style="border-top: 1px solid #383838"><td>Total</td><td></td><td>$3035</td></tr>
</table>
</section>

<!-- Resources
<section>
<h3>Resources</h3>
<ul>
    <li>Tangible Landscape website:  <a href="https://tangible-landscape.github.io">tangible-landscape.github.io</a></li>
    <li>Tangible Landscape wiki: <br><a href="https://github.com/tangible-landscape/grass-tangible-landscape/wiki">github.com/tangible-landscape/grass-tangible-landscape/wiki</a> </li>
    <li>Book: <a href="http://www.springer.com/us/book/9783319257730">
        <em>Tangible Modeling with Open Source GIS</em></a></li>
<li><a href="https://www.researchgate.net/publication/309458110_Immersive_Tangible_Geospatial_Modeling">
    Immersive Tangible Geospatial Modeling.</a> Proceedings of ACM SIGSPATIAL 2016.</li>
</ul>
</section>
-->

<!-- Live demo
<section>
<h3>Live demo</h3>
<p>Come see our demo!</p>
</section>
-->


<!-- Read more
<section>
<h2>Publications</h2>
<img width="20%" src="img/publications/tl_book_cover.png">
<p><small>Anna Petrasova, Brendan Harmon, Vaclav Petras, and Helena Mitasova. 2015. <a href="http://dx.doi.org/10.1007/978-3-319-25775-4">Tangible Modeling with Open Source GIS</a>, Springer International Publishing. DOI:<a href="http://dx.doi.org/10.1007/978-3-319-25775-4">http://dx.doi.org/10.1007/978-3-319-25775-4</a>
</small></p>
</section>
-->

<!--

<section>
<h2>Motivation for Tangible Interfaces for GIS</h2>
<ul>
    <li>Interaction through mouse, keyboard and display does not encourage creativity.</li>
    <li>Manipulating computer models is not intuitive and requires specialized software and training.</li>
    <li>Collaboration is restricted as typically only one user at a time can navigate and modify models. </li>

<aside class="notes">
    So why are we interested in Tangible interfaces?
    I am sure this photo shows a familiar setting -
we often get together around a screen to solve a geospatial problem or use mouse or touch
to manipulate 3D data on 2D screen. Such manipulation of data often requires knowledge of a specific,
often complex software, usually only single person can access the data
creating barriers to collaboration and creativity.
</aside>
</ul>

<img height="250px" src="img/collaboration_computer.JPG">
<img height="250px" src="img/art_rhino.jpg">
</section>

<section>
<h2>Tangible Landscape: real-time coupling with GIS</h2>
<iframe data-autoplay <iframe width="560" height="315" src="https://www.youtube.com/embed/Cd3cCQTGer4?rel=0&amp;showinfo=0;loop=1&amp;playlist=Cd3cCQTGer4" frameborder="0" allowfullscreen></iframe>
<img height="315px" src="img/system_schema.png">
<p>Tangible Landscape couples a digital and a physical model through
     a continuous cycle of 3D scanning, geospatial modeling, and projection.</p>
<aside class="notes">
    The new thing Tangible Landscape brings here is the real-time coupling
    with a full-fledged geographic information system. This means
    we can easily plug in and automate different analyses and geospatial workflows
    depending on the application,
    which brings lot of flexibility.
</aside>
</section>

<section>
<h2>Interactions</h2>
<img class="stretch" src="img/interactions.png">
<table width="100%">
        <col width="16%">
        <col width="18%">
        <col width="18%">
        <col width="18%">
        <col width="18%">
        <tr>
            <td style="vertical-align: middle; text-align:center; border-bottom: 0px; padding: 0;">surface
            <td style="vertical-align: middle; text-align:center; border-bottom: 0px; padding: 0;">points
            <td style="vertical-align: middle; text-align:center; border-bottom: 0px; padding: 0;">lines
            <td style="vertical-align: middle; text-align:center; border-bottom: 0px; padding: 0;" >areas
            <td style="vertical-align: middle; text-align:center; border-bottom: 0px; padding: 0;" >areas
        </tr>
</table>
<aside class="notes">
You have so far seen only sculpting sand with our hands, where we modify the continuous elevation surface. However some applications require different types of input data, such as objects. To make Tangible Landscape flexible in this regard, we developed multiple ways to interact with the physical models. Here we use a wooden marker to specify point locations on the landscape, for example view points or trailheads. Recently we have started to experiment with using laser pointer to draw objects, such as points, lines or polygons. Another option is to use colored sand to create polygons where the color represents certain attribute of the polygon and the height of the sand can represent intensity of that property. The most recent interaction we are testing now is creating areas using colored felt or paper of different shapes placed on the model.
These interactions can be combined to achieve intuitive interactions for particular application. Now I will show you some of the applications we developed for different study sites, using different geospatial models and each of them has different type of interaction.
</aside>
</section>

<section data-background-image="img/background_interaction_hands.png">
<h2>Application: erosion control</h2>
<p>Sculpting a check dam to retain storm water and reduce erosion
<img width="32%" src="img/felt/felt_4.jpg">
<img width="32%" src="img/felt/checkdam_1.jpg">
<img width="32%" src="img/felt/checkdam_2.jpg">
</section>

<section data-background-image="img/background_interaction_felt.png">
<h2>Application: erosion control</h2>
<p>Placing colored felt to modify land cover.
Adding grass (light green) and patches of trees (darker green)
changes the c-factor thus reducing erosion.
<img width="900px" src="img/felt.png">
<img width="23%" src="img/felt/felt_2.jpg">
<img width="23%" src="img/felt/felt_3.jpg">
<img width="23%" src="img/felt/felt_4.jpg">
</section>

<section data-background-image="img/background_interaction_hands_markers.png">
<h2>Applications: 3D soil moisture exploration</h2>
<img height="190px" src="img/subsurface_1.jpg">
<img height="190px" src="img/subsurface_2.jpg">
<img height="190px" src="img/subsurface_3.jpg">
<img width="80%" src="img/cross_section.png">
</section>

<section>
<h2>Serious games: coastal flooding</h2>
<img width="32%" src="img/tl_coastal_1s.png">
<img width="32%" src="img/tl_coastal_2s.png">
<img width="32%" src="img/tl_coastal_4s.png">
<p>Save houses from coastal flooding by building coastal defenses</p>
<p style="font-size:0.75em">Structured problem-solving with rules, challenging objectives, and scoring</p>
<aside class="notes">
    Recently there has been a lot of excitement about serious games and how we can use them to engage public in science. We thought Tangible Landscape would be a great tool for serious gaming, so let’s look at a coastal flooding game. We prepared this game for a public event and people playing the game were trying to protect the homes on the coast when a foredune is breached during a storm surge. With limited sand budget they tried different ways of building barriers and they learned pretty quickly that a breach in one place can cause flooding of houses which are far away from the breach.
</aside>
</section>

<section>
<h2> Coupling Tangible Landscape with IVE </h2>
<ul>
    <li> Better communicating the implications of landscape change </li>
    <li> Including design attributes in landscape planning process </li>
    <li> Assessing trade-offs between ecological and experiential quality (e.g., preferences, pyschological well-being) </li>
</ul>
<img class="stretch" src="img/flooding_secraf.jpg">

    <aside class="notes">

    As you have seen so far, Tangible Landscape represents the landscape as a projection-augmented model which is perceived in a bird’s-eye perspective. We aimed to complete the picture by representing the landscape similar to how we perceive in human-scale.
    So why it is important to include human perception ?

    First, this allows for a more tangible understanding and communicating the implications of landscape change that are important components in decision making and stake-holder participation.  What it means if some areas is flooded ? or how your living environment looks like after some restoration intervention ?
    Second, it allows bringing designers into the table and include attributes that they care about, like composition of landscape, coherence and etc.
    Third, given our growing understanding about the impact of landscapes on individual’s mental and physical health , it is is imperative to find those sweet spots where the ecological functioning and human-perception measures such as aesthetic evaluation and landscape preferences are balanced.

    </aside>
</section>

<section>
<h4> Landform and water bodies </h4>
<img class="stretch" src="img/coupling_case.jpg">
<div style="text-align:left">
<p2> <b>Interaction:</b> hand, sculpting knife </p2> <br/>
<p2> <b>3D processing:</b> terrain GeoTIFF raster and water polygon </p2> <br/>
<p2> <b>Simulation:</b> Water flow (r.sim.water), Ponding (r.fill.dir) </p2> <br/>
<p2> <b>Projection:</b> Water Surface Area, Mean depth</p2>
</div>

   <aside class="notes">
    Now lets see how some of the landscape features are processed through the application.
    For example, when landscape is manipulated with hand, a geotiff raster and a polygon related to water is processed.
    As users carves the landscape, Water flow and accumulation simulations are continuously projected onto the physical model.
    Numeric indicators about the depth and surface area of the retained water is projected.
    At the same time, point-cloud and water polygon is transferred to blender update the 3D model.
   </aside>

</section>

<section>
<h4> Vegetated surfaces  </h4>
<img class="stretch" src="img/coupling_case2.jpg">
<div style="text-align:left">
<p2> <b>Interaction:</b> Felt pieces, laser pointer </p2> <br/>
<p2> <b>3D processing:</b> Importing and populating species classes using the plants library </p2> <br/>
<p2> <b>Simulation:</b> Complexity, Heterogeneity, Biodiversity, Remediation capacity, Landscape structure analysis (r.li)  </p2> <br/>
<p2> <b>Projection:</b> Percent remediated, No of patches, patch richness, Shannon Diversity,  </p2> <br/>
</div>

  <aside class="notes">

  Users can design tree patches using colored felt pieces. They can either draw and cut their prefered shapes using scissors, or select from a library of cutouts with various shapes.
  Each color represents a landscape class based on National landcover datast classification, like decidous, evergreen etc. For instance in this example green denotes evergreen class and
  eastern pine trees, red means decidous and red maple, blue represents wetland species and river birch.
  Grass GIS applies image segmentation and classification to the scanned image to assign RGB values to their corresponding landscape classes.
  Using landscape structure analysis we compute and project various metrics related to landscape heterogeneity, biodiversity and complexity,
  which as you can see is projected below the landscape model.

  After importing, Blender applies a particle system modifier to populate corresponding species in each patch based on a predefined spacing and density,related to each specie.
  Some degree of randomness is applied to the size, rotation and sucsession of species to mimic the realworld representation of a patch.

  </aside>

</section>

<section>
<h4> Human views </h4>
<img class="stretch" src="img/coupling_case7.jpg">
<div style="text-align:left">
<p2> <b>Interaction:</b> Wooden marker, Laser pointer </p2> <br/>
<p2> <b>3D processing :</b> Importing polyline shapefiles and extrusion based on patch profile, assigning animation and camera path </p2> <br/>
<p2> <b>Simulation:</b> Viewshed </p2> <br/>
<p2> <b>Feedback:</b> Viewshed area, depth of view, viewdepth variation </p2> <br/>
</div>
 <aside class="notes">
   The 3D model is interactive so anytime during the interaction users can freely navigate in the environment and explore diffrent vantage points using the mouse.
   But we wanted to keep that feature interactive as well. We used wooden marker with colored tip, that denotes the viewers location and direction of view.
   The feature is exported as a polyline feature. Once imported in blender, The scene camera is then relocated to the line’s starting point and the direction of view is aligned to the line’s endpoint.
 </aside>
</section>

<section>
<h2>Tangible Landscape for communities</h2>
Platform for decision-making and science communication
    where people of different backgrounds can interact.
<p>
<img height="300px" src="img/collaboration1.JPG">
<img height="300px" src="img/SOD.jpg">
<p>
Making geospatial data and tools accessible to all
</section>

-->

<!-- This is a generated file. Do not edit. -->
        </div>  <!-- slides -->

    </div>  <!-- reveal -->

        <script src="lib/js/head.min.js"></script>
        <script src="js/reveal.js"></script>

        <script>

            // Full list of configuration options available here:
            // https://github.com/hakimel/reveal.js#configuration
            Reveal.initialize({
                // Display controls in the bottom right corner
                controls: false,

                // Display a presentation progress bar
                progress: true,

                center: true,

                // Display the page number of the current slide
                slideNumber: false,

                // Enable the slide overview mode
                overview: true,

                // Turns fragments on and off globally
                fragments: true,

                // The "normal" size of the presentation, aspect ratio will be preserved
                // when the presentation is scaled to fit different resolutions. Can be
                // specified using percentage units.
                 width: 1060,
                // height: 700,

                // Factor of the display size that should remain empty around the content
                margin: 0.05,  // increase?

                // Bounds for smallest/largest possible scale to apply to content
                minScale: 0.5,
                maxScale: 5.0,

                theme: Reveal.getQueryHash().theme,  // available themes are in /css/theme
                transition: Reveal.getQueryHash().transition || 'none', // default/cube/page/concave/zoom/linear/fade/none

                // Push each slide change to the browser history
                history: true,
                // Enable keyboard shortcuts for navigation
                keyboard: true,

                // Vertical centering of slides
                center: true,

                // Enables touch navigation on devices with touch input
                touch: true,

                // Loop the presentation
                loop: false,
                // Flags if the presentation is running in an embedded mode,
                // i.e. contained within a limited portion of the screen
                embedded: false,

                // Number of milliseconds between automatically proceeding to the
                // next slide, disabled when set to 0, this value can be overwritten
                // by using a data-autoslide attribute on your slides
                autoSlide: 0,

                // Stop auto-sliding after user input
                autoSlideStoppable: true,

                // Enable slide navigation via mouse wheel
                mouseWheel: false,

                // Hides the address bar on mobile devices
                hideAddressBar: true,

                // Opens links in an iframe preview overlay
                previewLinks: false,

                // Transition speed
                transitionSpeed: 'default', // default/fast/slow

                // Transition style for full page slide backgrounds
                backgroundTransition: 'none', // default/none/slide/concave/convex/zoom

                // Number of slides away from the current that are visible
                viewDistance: 3,

                // Parallax background image
                //parallaxBackgroundImage: '', // e.g. "'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'"

                // Parallax background size
                //parallaxBackgroundSize: '' // CSS syntax, e.g. "2100px 900px"
                // Optional libraries used to extend on reveal.js
                dependencies: [
                    { src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
                    { src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
                    { src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
                    { src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
                    { src: 'plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
                    { src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } },
                    { src: 'plugin/math/math.js', async: true }
                ]
            });

        </script>

    </body>
</html>
